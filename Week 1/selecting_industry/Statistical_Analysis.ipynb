{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97a30fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ee80d",
   "metadata": {},
   "source": [
    "open csv file and save it as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6554707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'filtered_stock.csv'\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Read data from the CSV file\n",
    "with open(csv_file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    for row in reader:\n",
    "        key = row['Key']\n",
    "        values = row['Values'].split(', ')  # Split the values by commas\n",
    "        data[key] = values\n",
    "        \n",
    "# Now 'data' contains the dictionary you originally wrote to the CSV file\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4ce89",
   "metadata": {},
   "source": [
    "Fetch the earning call dates for each companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab8831c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "earn_dict = {}\n",
    "\n",
    "for inds in data:\n",
    "    file_loc = '../sectors/' + inds\n",
    "    for cmp in data[inds]:\n",
    "        folder_names = glob.glob(file_loc + '/' + cmp + '/*')\n",
    "        \n",
    "        for name in folder_names:\n",
    "            if 'names' in name:\n",
    "                folder_names.remove(name)\n",
    "                \n",
    "        earn_dates = []\n",
    "        for earn_logs in folder_names:\n",
    "            file = open(earn_logs, encoding='utf8')\n",
    "            earn_log = csv.reader(file)\n",
    "            next(earn_log)\n",
    "            next(earn_log)\n",
    "            earn_date = next(earn_log)\n",
    "            earn_dates.append(str(earn_date[0]).split(' ')[0])\n",
    "            file.close()\n",
    "        earn_dict[cmp] = earn_dates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c8d28",
   "metadata": {},
   "source": [
    "Write the earning call date dictionary as csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d629c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'earning_call_dates.csv'\n",
    "\n",
    "with open(csv_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Key', 'Values']  # Define the CSV header\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write data from the dictionary to the CSV\n",
    "    for key, values in earn_dict.items():\n",
    "        writer.writerow({'Key': key, 'Values': ', '.join(values)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ec9d3",
   "metadata": {},
   "source": [
    "Create folders for each industires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "235b601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inds in data:\n",
    "    os.mkdir(inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b6755",
   "metadata": {},
   "source": [
    "Create a dataframe for each company with stock prices for various dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65956413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "            Day +1  Day +2  Day +7  Day +28\n",
      "2012-08-07       0       0      -1        0\n",
      "2012-11-15      -1      -3      -5      -13\n",
      "2013-02-21       0       6       4       32\n",
      "2013-05-16       0       0       3        0\n",
      "2013-11-05       0      -2      -2      -11\n",
      "2014-11-12      -1      -6       0      -25\n",
      "2015-07-31       1       4       0       -6\n",
      "2015-11-10      -3      -9      -9      -50\n",
      "2016-02-11       0      17      31       70\n",
      "2016-06-03      -2       8      11        0\n",
      "2016-07-30       0       6      10       18\n",
      "2016-10-31      -3       0      -3       22\n",
      "2017-02-24       0       4      14       34\n",
      "2017-05-19       0       0      -2        9\n",
      "2017-07-27      -2       0       8       19\n",
      "2017-11-01       0       0       5       -8\n",
      "2018-02-15      -1      -3       3        0\n",
      "2018-05-30       0      12      22       17\n",
      "2018-07-27       0       7       6       -4\n",
      "2018-11-10       2      -5      -8      -16\n",
      "2019-02-19       0      -8      -7       -6\n",
      "2019-05-28      -1      -4      -9       -5\n",
      "2019-09-04       1       0       1      -17\n",
      "2020-06-09       0      -5      -2       -9\n",
      "2020-08-06      -1       0       2      -11\n",
      "2020-11-14       2       3       3       17\n",
      "2021-02-16       0      -5      -7       -7\n",
      "2021-05-08       4       4      -4       -7\n",
      "2021-07-29       0       0      -3       15\n",
      "2021-11-05       1       2      -1       -4\n",
      "2022-03-10       2       2       2      -12\n",
      "2022-05-26       0       5       5      -15\n",
      "2022-07-28      -1      -4      -4       -9\n",
      "2022-11-11       0       3       1       -9\n"
     ]
    }
   ],
   "source": [
    "date_format = '%Y-%m-%d'\n",
    "currwd = os.getcwd()\n",
    "\n",
    "for inds in data:\n",
    "        \n",
    "    earn_impc_price = pd.DataFrame(columns = ['Day +1', 'Day +2', 'Day +7', 'Day +28'])\n",
    "    earn_impc_perc = pd.DataFrame(columns = ['Day +1', 'Day +2', 'Day +7', 'Day +28'])\n",
    "    \n",
    "    for cmp in data[inds]:\n",
    "        price_df = pd.DataFrame(columns=['Day 0', 'Day +1', 'Day +2', 'Day +7', 'Day +28'])\n",
    "        price_gap = pd.DataFrame(columns=['Day +1', 'Day +2', 'Day +7', 'Day +28'])\n",
    "        price_perc = pd.DataFrame(columns=['Day +1', 'Day +2', 'Day +7', 'Day +28'])\n",
    "        count = 0\n",
    "                \n",
    "        for earn_date in earn_dict[cmp]:\n",
    "                        \n",
    "            count += 1\n",
    "            \n",
    "            datetime_earn_date = datetime.strptime(earn_date, date_format)\n",
    "            yfdata = yf.download(cmp, earn_date)\n",
    "            datetime_yfdata_date = datetime.strptime(str(yfdata.index[0]).split(' ')[0], date_format)\n",
    "            \n",
    "            while(datetime_earn_date < datetime_yfdata_date):\n",
    "                temp_date = datetime_earn_date - timedelta(days=1)\n",
    "                yfdata = yf.download(cmp, temp_date.strftime(date_format))\n",
    "                datetime_yfdata_date = datetime.strptime(str(yfdata.index[0]).split(' ')[0], date_format)\n",
    "            \n",
    "            #print(yfdata)\n",
    "            \n",
    "            df_row = {'Day 0': yfdata.loc[yfdata.index[0]].at['Close'], \n",
    "                       'Day +1': yfdata.loc[yfdata.index[1]].at['Open'], \n",
    "                       'Day +2': yfdata.loc[yfdata.index[2]].at['Open'], \n",
    "                       'Day +7': yfdata.loc[yfdata.index[5]].at['Open'], \n",
    "                       'Day +28': yfdata.loc[yfdata.index[20]].at['Open']}\n",
    "            \n",
    "            #print(df_row)\n",
    "            \n",
    "            price_df.loc[earn_date] = df_row\n",
    "            \n",
    "            gap_row = {'Day +1': df_row['Day +1'] - df_row['Day 0'], \n",
    "                       'Day +2': df_row['Day +2'] - df_row['Day 0'], \n",
    "                       'Day +7': df_row['Day +7'] - df_row['Day 0'], \n",
    "                       'Day +28': df_row['Day +28'] - df_row['Day 0']}\n",
    "            \n",
    "            price_gap.loc[earn_date] = gap_row\n",
    "            \n",
    "            perc_row = {'Day +1': int((df_row['Day +1'] / df_row['Day 0'])*100 -100), \n",
    "                       'Day +2': int((df_row['Day +2'] / df_row['Day 0'])*100 - 100), \n",
    "                       'Day +7': int((df_row['Day +7'] / df_row['Day 0'])*100 - 100), \n",
    "                       'Day +28': int((df_row['Day +28'] / df_row['Day 0'])*100 - 100)}\n",
    "            \n",
    "            price_perc.loc[earn_date] = perc_row\n",
    "            \n",
    "        #print(price_df)\n",
    "        #print(price_gap)\n",
    "        #print(price_perc)\n",
    "        \n",
    "        gap_sum_1 = 0\n",
    "        gap_sum_2 = 0\n",
    "        gap_sum_7 = 0\n",
    "        gap_sum_28 = 0\n",
    "        \n",
    "        for chng in price_gap['Day +1']:\n",
    "            gap_sum_1 += abs(chng)\n",
    "        \n",
    "        for chng in price_gap['Day +2']:\n",
    "            gap_sum_2 += abs(chng)\n",
    "            \n",
    "        for chng in price_gap['Day +7']:\n",
    "            gap_sum_7 += abs(chng)\n",
    "        \n",
    "        for chng in price_gap['Day +28']:\n",
    "            gap_sum_28 += abs(chng)\n",
    "            \n",
    "        gap_avg_row = {'Day +1': gap_sum_1 / count, \n",
    "                       'Day +2': gap_sum_2 / count, \n",
    "                       'Day +7': gap_sum_7 / count, \n",
    "                       'Day +28': gap_sum_28 / count}\n",
    "        \n",
    "        earn_impc_price.loc[cmp] = gap_avg_row\n",
    "        #print(earn_impc_price)\n",
    "        \n",
    "        perc_sum_1 = 0\n",
    "        perc_sum_2 = 0\n",
    "        perc_sum_7 = 0\n",
    "        perc_sum_28 = 0\n",
    "        \n",
    "        for chng in price_perc['Day +1']:\n",
    "            perc_sum_1 += abs(chng)\n",
    "        \n",
    "        for chng in price_perc['Day +2']:\n",
    "            perc_sum_2 += abs(chng)\n",
    "            \n",
    "        for chng in price_perc['Day +7']:\n",
    "            perc_sum_7 += abs(chng)\n",
    "        \n",
    "        for chng in price_perc['Day +28']:\n",
    "            perc_sum_28 += abs(chng)\n",
    "            \n",
    "        perc_avg_row = {'Day +1': perc_sum_1 / count, \n",
    "                       'Day +2': perc_sum_2 / count, \n",
    "                       'Day +7': perc_sum_7 / count, \n",
    "                       'Day +28': perc_sum_28 / count}\n",
    "        \n",
    "        earn_impc_perc.loc[cmp] = perc_avg_row\n",
    "        #print(earn_impc_perc)\n",
    "        temp = earn_impc_perc\n",
    "        break\n",
    "        \n",
    "    #print(earn_impc_price)\n",
    "    #print(earn_impc_perc)\n",
    "    earn_impc_price.to_csv(currwd + '/' + inds + '/' + 'price_gap.csv')\n",
    "    earn_impc_perc.to_csv(currwd + '/' + inds + '/' + 'price_perc.csv')\n",
    "    break\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1d0b3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day +1</th>\n",
       "      <th>Day +2</th>\n",
       "      <th>Day +7</th>\n",
       "      <th>Day +28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SB</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>4.029412</td>\n",
       "      <td>5.823529</td>\n",
       "      <td>14.617647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day +1    Day +2    Day +7    Day +28\n",
       "SB  0.852941  4.029412  5.823529  14.617647"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef44c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('miniforge3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f8639949fcdb6d5981adbfd202ad70a2c40fda03c9a34cd77a04b46e02223e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
